# Azure-Medallion-Data-Pipeline
End-to-end Azure Data Engineering project implementing Medallion Architecture with Data Factory, Databricks, Synapse Analytics, and Power BI.


## ğŸ“Œ Overview
This repository showcases a **comprehensive end-to-end Azure Data Engineering pipeline** built using the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold).  
It demonstrates **real-world, production-grade design patterns** with a focus on **reusability, scalability, and security**.

The project covers:
- **Data ingestion** using **Azure Data Factory (ADF)** with **dynamic pipelines**
- **Data transformation** using **Azure Databricks** and **PySpark**
- **Data serving** using **Azure Synapse Analytics**
- **Visualization & reporting** via **Power BI**
- **Secure service connections** with **Azure Managed Identities**

This architecture is commonly used in modern data engineering solutions, making it ideal for **interview preparation** and **practical learning**.

---

## ğŸ— Architecture
![Architecture Diagram](<img width="1366" height="768" alt="20250815_1809_image" src="https://github.com/user-attachments/assets/6c5d22b9-e86d-420e-a92d-909fb6a12dcf" />
)

**Workflow:**
1. **Data Source** â€“ HTTP API or external dataset
2. **Data Ingestion (Bronze Layer)** â€“ Raw data is ingested into Azure Data Lake Gen2 using **dynamic pipelines** in ADF
3. **Data Transformation (Silver Layer)** â€“ Databricks cleanses and transforms data into analytics-friendly format
4. **Data Serving (Gold Layer)** â€“ Synapse Analytics stores curated data for reporting
5. **Reporting & Visualization** â€“ Power BI consumes data from Synapse for dashboards and insights

---

## ğŸ”„ Project Workflow in Detail

### **1ï¸âƒ£ Bronze Layer â€“ Data Ingestion**
- Ingestion handled by **Azure Data Factory**
- **Dynamic pipelines** with:
  - Parameters for dataset paths
  - `ForEach` activity for multiple file ingestion
- Raw data stored in **Data Lake Gen2** (Bronze zone)
- Supports API ingestion directly without manual CSV uploads

### **2ï¸âƒ£ Silver Layer â€“ Data Transformation**
- **Azure Databricks** with **PySpark** for large-scale processing
- Key transformations:
  - Schema enforcement
  - String and date manipulations
  - Aggregations and joins
  - Data quality checks
- Stores cleaned data in **Data Lake Gen2** (Silver zone)

### **3ï¸âƒ£ Gold Layer â€“ Data Serving**
- Data loaded into **Azure Synapse Analytics**
- **External tables** and **views** created for optimized access
- Uses **CETAS** (`CREATE EXTERNAL TABLE AS SELECT`) for efficiency
- **RBAC** and **Managed Identities** for secure connections

### **4ï¸âƒ£ Reporting**
- Synapse **serverless SQL endpoints** connected to **Power BI**
- Dashboards show business insights based on curated Gold data

---

## âœ¨ Key Features
- ğŸš€ **End-to-End Azure Data Engineering pipeline**
- ğŸ”„ **Dynamic pipelines** in ADF for multi-file ingestion
- ğŸ’ **Medallion Architecture** for data organization
- âš¡ **Scalable Spark transformations** in Databricks
- ğŸ” **Secure connections** using Managed Identities & RBAC
- ğŸ“Š **Interactive dashboards** in Power BI
- ğŸ§° **Reusable components** (parameterized datasets, linked services, JSON-driven configs)




